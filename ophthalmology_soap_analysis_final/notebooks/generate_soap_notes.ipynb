{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBv8Zr_wPQQz",
    "outputId": "6d4fa91a-d5d5-47dc-c7fb-8a1934114941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Cell: Install Required Libraries\n",
    "!pip install -q langchain_dartmouth PyPDF2 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24E9syZWPRps",
    "outputId": "333f16e4-0e59-4d9f-832a-f893f114cc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter DARTMOUTH_API_KEY: ··········\n",
      "Enter DARTMOUTH_CHAT_API_KEY: ··········\n",
      "Keys set: True True\n",
      "Selected model: openai.gpt-5-mini-2025-08-07\n"
     ]
    }
   ],
   "source": [
    "# Cell: Load API keys and model from config file\n",
    "import os\n",
    "try:\n",
    "    import config\n",
    "    os.environ[\"DARTMOUTH_API_KEY\"] = config.DARTMOUTH_API_KEY\n",
    "    os.environ[\"DARTMOUTH_CHAT_API_KEY\"] = config.DARTMOUTH_CHAT_API_KEY\n",
    "    SELECTED_MODEL = getattr(config, \"SELECTED_MODEL\", \"openai.gpt-5-mini-2025-08-07\")\n",
    "    print(\"API keys loaded from config.\")\n",
    "except ImportError as e:\n",
    "    raise RuntimeError(\"Please create a config.py file with your API keys as shown in config_template.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_NFOsf8oPTbf",
    "outputId": "70af140e-55b2-4767-c197-1b74f2026368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "BASE_FOLDER   → /content/drive/MyDrive/Ophthalmology Live Folder\n",
      "OUTPUT_FOLDER → /content/drive/MyDrive/Ophthalmology Live Folder/Case Study Output\n",
      "CLEAN DOC ID  → 1xoVkMUsRF8ozwoBnq9QSJduZcDuAtgE58rn5dqhoPKw\n",
      "ADV DOC ID    → 1ayKJwGEAG-yPTpz2yyLo0pPSGqnTW4fMcMNeqWdwPVs\n"
     ]
    }
   ],
   "source": [
    "# Read local case study documents (Word files) instead of using local Drive/Docs\n",
    "import docx\n",
    "import os\n",
    "\n",
    "BASE_FOLDER = '../data'\n",
    "CLEAN_CASE_STUDY_PATH = os.path.join(BASE_FOLDER, 'clean_case_studies.docx')\n",
    "ADVERSARIAL_CASE_STUDY_PATH = os.path.join(BASE_FOLDER, 'adversarial_case_studies.docx')\n",
    "\n",
    "\n",
    "def read_docx(path):\n",
    "    doc = docx.Document(path)\n",
    "    return '\n",
    "'.join([para.text for para in doc.paragraphs])\n",
    "\n",
    "clean_case_study_text = read_docx(CLEAN_CASE_STUDY_PATH)\n",
    "adversarial_case_study_text = read_docx(ADVERSARIAL_CASE_STUDY_PATH)\n",
    "\n",
    "print('Loaded clean case study text (length):', len(clean_case_study_text))\n",
    "print('Loaded adversarial case study text (length):', len(adversarial_case_study_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrSfRToWPVtt"
   },
   "outputs": [],
   "source": [
    "# Helpers for local Docs removed since we use local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPxbkEZGPYMj",
    "outputId": "3912ee9f-2fdd-4096-a69c-5fe714bb20e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 clean cases and 98 adversarial cases.\n",
      "Example CLEAN case: CASE 1: Acute Follicular Conjunctivitis\n",
      "Example ADV case: CASE 1: Acute Follicular Conjunctivitis\n"
     ]
    }
   ],
   "source": [
    "# Cell: Parse cases from local Word document instead of local Doc\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "def extract_cases_from_docx_text(text: str):\n",
    "    \"\"\"Parse the combined text of a local Word doc into case dictionary.\"\"\"\n",
    "    cases = OrderedDict()\n",
    "    # Pattern matches \"CASE\" followed by number and dash or em-dash\n",
    "    pattern = re.compile(r\"CASE\\s*(\\d+)\\s*[—-]\", re.IGNORECASE)\n",
    "    parts = pattern.split(text)\n",
    "    # parts[0] is header/preamble; then pairs of number and content\n",
    "    for i in range(1, len(parts), 2):\n",
    "        case_num = parts[i].strip()\n",
    "        case_text = parts[i+1].strip() if (i+1) < len(parts) else \"\"\n",
    "        cases[case_num] = case_text\n",
    "    return cases\n",
    "\n",
    "# Example usage:\n",
    "# raw_text = read_docx(CLEAN_CASE_STUDY_PATH)\n",
    "# cases = extract_cases_from_docx_text(raw_text)\n",
    "# print(cases.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsyDyldVPaJU"
   },
   "outputs": [],
   "source": [
    "# Cell 6: Field and Section Definitions\n",
    "SUBJECTIVE_FIELDS_1 = [\n",
    "    \"CHIEF COMPLAINT\", \"DURATION\", \"LATERALITY\", \"PATIENT QUOTES\",\n",
    "    \"HISTORY OF PRESENT ILLNESS\", \"History Narrative\", \"Symptom Onset\",\n",
    "    \"Symptom Duration\", \"Progression\", \"Characteristics\"\n",
    "]\n",
    "SUBJECTIVE_FIELDS_2 = [\n",
    "    \"Aggravating Factors\", \"Alleviating Factors\", \"Associated Symptoms\", \"Previous Episodes\",\n",
    "    \"Prior Treatments\", \"Impact on Daily Activities\", \"Systemic Symptoms\",\n",
    "    \"Recent Travel\", \"Contacts with Similar Symptoms\", \"Risk Factors\"\n",
    "]\n",
    "OBJECTIVE_FIELDS_1 = [\n",
    "    \"Vitals – Blood Pressure\", \"Vitals – Pulse\", \"Vitals – Temperature\", \"Vitals – Respirations\",\n",
    "    \"Visual Acuity – Uncorrected Right\", \"Visual Acuity – Corrected Right\",\n",
    "    \"Visual Acuity – Uncorrected Left\", \"Visual Acuity – Corrected Left\",\n",
    "    \"Visual Acuity – Near Acuity\", \"Visual Acuity – Method\",\n",
    "    \"Intraocular Pressure – Right\", \"Intraocular Pressure – Left\", \"Intraocular Pressure – Method\"\n",
    "]\n",
    "OBJECTIVE_FIELDS_2 = [\n",
    "    \"External Exam – Lids/Lashes\", \"External Exam – Conjunctiva/Sclera\", \"External Exam – Lacrimal System\", \"External Exam – Orbit\",\n",
    "    \"Anterior Segment – Cornea\", \"Anterior Segment – Anterior Chamber\", \"Anterior Segment – Iris\",\n",
    "    \"Anterior Segment – Angle\", \"Anterior Segment – Lens\"\n",
    "]\n",
    "OBJECTIVE_FIELDS_3 = [\n",
    "    \"Pupils – Size/Shape\", \"Pupils – Reaction to Light\", \"Pupils – Reaction to Near\", \"Pupils – RAPD\", \"Pupils – Other\",\n",
    "    \"Extraocular Movements\", \"Slit Lamp Exam Description\",\n",
    "    \"Fundus Exam – Optic Nerve\", \"Fundus Exam – Macula\", \"Fundus Exam – Vessels\", \"Fundus Exam – Periphery\"\n",
    "]\n",
    "ASSESSMENT_FIELDS = [\n",
    "    \"Assessment Narrative\", \"Primary Diagnosis\", \"Secondary Diagnoses\",\n",
    "    \"Differential Diagnosis\", \"Severity\", \"Laterality\", \"Complications\"\n",
    "]\n",
    "PLAN_FIELDS = [\n",
    "    \"All Medications\", \"All Procedures\", \"Follow-Up Instructions\",\n",
    "    \"Patient Education\", \"Referrals\", \"Work Restrictions\", \"Emergency Instructions\"\n",
    "]\n",
    "REQUIRED_HEADERS = {\n",
    "    \"subjective1\": SUBJECTIVE_FIELDS_1,\n",
    "    \"subjective2\": SUBJECTIVE_FIELDS_2,\n",
    "    \"objective1\": OBJECTIVE_FIELDS_1,\n",
    "    \"objective2\": OBJECTIVE_FIELDS_2,\n",
    "    \"objective3\": OBJECTIVE_FIELDS_3,\n",
    "    \"assessment\": ASSESSMENT_FIELDS,\n",
    "    \"plan\": PLAN_FIELDS,\n",
    "}\n",
    "SECTION_ORDER = [\n",
    "    \"subjective1\", \"subjective2\",\n",
    "    \"objective1\", \"objective2\", \"objective3\",\n",
    "    \"assessment\", \"plan\"\n",
    "]\n",
    "SECTION_LABELS = {\n",
    "    \"subjective1\": \"SUBJECTIVE\",\n",
    "    \"subjective2\": \"SUBJECTIVE (cont.)\",\n",
    "    \"objective1\": \"OBJECTIVE EXAM\",\n",
    "    \"objective2\": \"OBJECTIVE EXAM (cont.)\",\n",
    "    \"objective3\": \"OBJECTIVE EXAM (cont. 2)\",\n",
    "    \"assessment\": \"ASSESSMENT\",\n",
    "    \"plan\": \"PLAN\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJAO5SYoPcM6"
   },
   "outputs": [],
   "source": [
    "# Cell 7: Run configuration with manual start indices and optional limits\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Which sets to run\n",
    "RUN_CLEAN = True\n",
    "RUN_ADVERSARIAL = True\n",
    "\n",
    "# Manual start points (case index numbers from the docs)\n",
    "START_CLEAN_AT = 1        # e.g., 40 to start at CLEAN case 40\n",
    "START_ADVERSARIAL_AT = 1  # e.g., 50 to start at ADV case 50\n",
    "\n",
    "# Optional limits (None means no limit) — helpful for quick tests\n",
    "MAX_CASES_CLEAN = 98       # e.g., 1–3 for testing; set None to run all\n",
    "MAX_CASES_ADVERSARIAL = 98\n",
    "\n",
    "# Checkpoint behavior\n",
    "SKIP_COMPLETED = True      # skip cases already complete in checkpoint\n",
    "RESET_CHECKPOINTS = True  # set True once to clear old checkpoints\n",
    "\n",
    "# LLM retry config\n",
    "MAX_RETRIES = 10\n",
    "PRINT_FAILED_OUTPUTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZblnQIOpPeoT",
    "outputId": "55e15d1d-6b3c-4e68-e8a0-8d3dd66c6e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running smoke test against: openai.gpt-5-mini-2025-08-07\n",
      "Smoke test response: OK\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: LLM client, UTC timestamp, quota detection, smoke test\n",
    "import time, random, json\n",
    "from datetime import datetime, timezone\n",
    "try:\n",
    "    from datetime import UTC  # Py 3.12+\n",
    "except ImportError:\n",
    "    UTC = timezone.utc\n",
    "\n",
    "from langchain_dartmouth.llms import ChatDartmouthCloud\n",
    "\n",
    "# gpt-5 requires temperature=1\n",
    "GENERATION_KW = dict(temperature=1)\n",
    "\n",
    "def now_iso():\n",
    "    return datetime.now(UTC).replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "def get_llm():\n",
    "    # Always and only use your selected model, with required params\n",
    "    return ChatDartmouthCloud(model_name=SELECTED_MODEL, temperature=1)\n",
    "\n",
    "def call_llm_text(llm, messages, retries=MAX_RETRIES, sleep_base=1.2):\n",
    "    last_exc = None\n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            resp = llm.invoke(messages, **GENERATION_KW)\n",
    "            # Common response shapes\n",
    "            if isinstance(resp, str):\n",
    "                return resp.strip()\n",
    "            if hasattr(resp, \"content\") and isinstance(resp.content, str):\n",
    "                return resp.content.strip()\n",
    "            if isinstance(resp, dict):\n",
    "                if isinstance(resp.get(\"content\"), str):\n",
    "                    return resp[\"content\"].strip()\n",
    "                if isinstance(resp.get(\"text\"), str):\n",
    "                    return resp[\"text\"].strip()\n",
    "            if hasattr(resp, \"generations\"):\n",
    "                return resp.generations[0][0].text.strip()\n",
    "            text = str(resp).strip()\n",
    "            if text:\n",
    "                return text\n",
    "            raise RuntimeError(\"Empty response\")\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            time.sleep(sleep_base * (1.5 ** (attempt-1)) + random.random())\n",
    "    raise last_exc\n",
    "\n",
    "def is_quota_or_rate_error(exc: Exception) -> bool:\n",
    "    s = str(exc).lower()\n",
    "    return any(k in s for k in [\n",
    "        \"insufficient_quota\", \"quota\", \"rate limit\", \"429\",\n",
    "        \"out of tokens\", \"insufficient tokens\", \"credit\",\n",
    "        \"payment_required\", \"maximum context length\", \"context_length_exceeded\",\n",
    "        \"token limit\"\n",
    "    ])\n",
    "\n",
    "# Smoke test (fail fast if model is not reachable or params rejected)\n",
    "print(\"Running smoke test against:\", SELECTED_MODEL)\n",
    "try:\n",
    "    probe = get_llm()\n",
    "    msg = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a test probe.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Reply with exactly: OK\"}\n",
    "    ]\n",
    "    out = call_llm_text(probe, msg, retries=1)\n",
    "    print(\"Smoke test response:\", out)\n",
    "except Exception as e:\n",
    "    print(\"SMOKE TEST FAILED for model:\", SELECTED_MODEL)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDv43KhoPg-0"
   },
   "outputs": [],
   "source": [
    "# Cell 9: Checkpoint utilities (per-field durable save)\n",
    "import os\n",
    "\n",
    "def sanitize_filename(s: str) -> str:\n",
    "    return \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\", \" \", \".\") else \"_\" for ch in s).strip()\n",
    "\n",
    "def checkpoint_path(out_prefix: str) -> str:\n",
    "    return os.path.join(\n",
    "        OUTPUT_FOLDER,\n",
    "        f\"checkpoint_{out_prefix}_{sanitize_filename(SELECTED_MODEL)}.json\"\n",
    "    )\n",
    "\n",
    "def load_checkpoint(out_prefix: str) -> dict:\n",
    "    path = checkpoint_path(out_prefix)\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        data.setdefault(\"model\", SELECTED_MODEL)\n",
    "        data.setdefault(\"out_prefix\", out_prefix)\n",
    "        data.setdefault(\"cases\", {})\n",
    "        return data\n",
    "    return {\"model\": SELECTED_MODEL, \"out_prefix\": out_prefix, \"cases\": {}}\n",
    "\n",
    "def save_checkpoint(out_prefix: str, ckpt: dict):\n",
    "    path = checkpoint_path(out_prefix)\n",
    "    tmp = path + \".tmp\"\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(ckpt, f, ensure_ascii=False, indent=2)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def case_key(case_index: int, case_title: str) -> str:\n",
    "    return f\"Case {case_index:02d} {case_title}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSFwt_eAPk8N"
   },
   "outputs": [],
   "source": [
    "# Cell 10: Field extraction with concise instructions and per-field checkpoint saves\n",
    "\n",
    "def assemble_note_from_fields_minimal(fields_dict: dict) -> str:\n",
    "    # Minimal assembly for intermediate saves; final doc rendering is applied later\n",
    "    out_sections = []\n",
    "    for section in SECTION_ORDER:\n",
    "        fields = REQUIRED_HEADERS[section]\n",
    "        lines = [f\"{field}: {fields_dict.get(field, 'N/A')}\" for field in fields]\n",
    "        out_sections.append(SECTION_LABELS.get(section, section).upper() + \"\\n\" + \"\\n\".join(lines))\n",
    "    return \"\\n\\n\".join(out_sections)\n",
    "\n",
    "def extract_fields_for_case(llm, case_text: str, out_prefix: str, k: str, starting_fields: dict = None, verbose=False) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts fields one-by-one, saving checkpoint after each field.\n",
    "    On quota/rate error, saves partial and raises to stop gracefully.\n",
    "    Prompts tuned to be medically accurate AND concise (avoid laundry lists).\n",
    "    \"\"\"\n",
    "    ckpt = load_checkpoint(out_prefix)\n",
    "    fields_done = dict(starting_fields or {})\n",
    "\n",
    "    # Ordered list of fields\n",
    "    all_fields_in_order = []\n",
    "    for section in SECTION_ORDER:\n",
    "        all_fields_in_order.extend(REQUIRED_HEADERS[section])\n",
    "\n",
    "    for field in all_fields_in_order:\n",
    "        if field in fields_done and (fields_done[field] or fields_done[field] == \"N/A\"):\n",
    "            continue\n",
    "\n",
    "        if field in OBJECTIVE_FIELDS_1:\n",
    "            system_line = (\n",
    "                \"You are an ophthalmology scribe. \"\n",
    "                \"For the field below, output a medically plausible, typical, or case-appropriate value even if not explicitly stated. \"\n",
    "                \"Only respond with 'N/A' if it is truly impossible to infer a reasonable value.\"\n",
    "            )\n",
    "        elif field in PLAN_FIELDS:\n",
    "            system_line = (\n",
    "                \"You are a professional ophthalmology medical scribe. \"\n",
    "                \"Return ONLY the value for the named field. Be concise. \"\n",
    "                \"Prioritize items explicitly stated in the case; if you infer typical care, include at most one core, standard-of-care item. \"\n",
    "                \"Avoid exhaustive or speculative lists. If truly unknown or not applicable, reply 'N/A'.\"\n",
    "            )\n",
    "        elif field == \"Differential Diagnosis\":\n",
    "            system_line = (\n",
    "                \"You are a professional ophthalmology medical scribe. \"\n",
    "                \"Return ONLY the value for 'Differential Diagnosis'. Be concise and list the 2–4 most likely differentials; \"\n",
    "                \"separate them with semicolons. If not applicable, reply 'N/A'.\"\n",
    "            )\n",
    "        else:\n",
    "            system_line = (\n",
    "                \"You are a professional ophthalmology medical scribe. \"\n",
    "                \"Given the case below, infer ONLY the value for the named field. \"\n",
    "                \"If not explicitly stated but typical or reasonably deducible, provide a concise inference. \"\n",
    "                \"Use 'N/A' strictly if not relevant or impossible to infer.\"\n",
    "            )\n",
    "\n",
    "        user_line = (\n",
    "            f\"Case:\\n{case_text}\\n\\n\"\n",
    "            f\"Field to extract: {field}\\n\"\n",
    "            f\"Return only the value for this field, no label or extra text.\"\n",
    "        )\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_line},\n",
    "            {\"role\": \"user\", \"content\": user_line}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            ans = call_llm_text(llm, messages)\n",
    "            clean_ans = (ans or \"\").strip().replace(\"\\n\", \" \")\n",
    "            if not clean_ans:\n",
    "                clean_ans = \"N/A\"\n",
    "            fields_done[field] = clean_ans\n",
    "            if verbose:\n",
    "                print(f\"{field}: {clean_ans}\")\n",
    "        except Exception as e:\n",
    "            if is_quota_or_rate_error(e):\n",
    "                # Save partial progress and stop\n",
    "                case_entry = ckpt[\"cases\"].setdefault(k, {\"status\": \"partial\", \"fields\": {}, \"title\": k, \"last_updated\": now_iso()})\n",
    "                case_entry[\"fields\"].update(fields_done)\n",
    "                case_entry[\"status\"] = \"partial\"\n",
    "                case_entry[\"last_updated\"] = now_iso()\n",
    "                case_entry[\"note\"] = assemble_note_from_fields_minimal(case_entry[\"fields\"])\n",
    "                save_checkpoint(out_prefix, ckpt)\n",
    "                raise\n",
    "            else:\n",
    "                if PRINT_FAILED_OUTPUTS:\n",
    "                    print(f\"Non-quota exception for {k} – {field}: {e}\")\n",
    "                fields_done[field] = \"N/A\"\n",
    "\n",
    "        # Save after each field\n",
    "        case_entry = ckpt[\"cases\"].setdefault(k, {\"status\": \"partial\", \"fields\": {}, \"title\": k, \"last_updated\": now_iso()})\n",
    "        case_entry[\"fields\"].update(fields_done)\n",
    "        case_entry[\"status\"] = \"partial\"\n",
    "        case_entry[\"last_updated\"] = now_iso()\n",
    "        case_entry[\"note\"] = assemble_note_from_fields_minimal(case_entry[\"fields\"])\n",
    "        save_checkpoint(out_prefix, ckpt)\n",
    "\n",
    "    return fields_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPlWgHxOPp6L"
   },
   "outputs": [],
   "source": [
    "# Cell 11: Human-readable rendering (no bullets; always show headers; omit N/A lines)\n",
    "# Also write both local Doc and combined .txt file\n",
    "\n",
    "PRETTY_SECTION_LABELS = {\n",
    "    \"subjective1\": \"Subjective\",\n",
    "    \"subjective2\": \"Subjective (cont.)\",\n",
    "    \"objective1\": \"Objective Exam\",\n",
    "    \"objective2\": \"Objective Exam (cont.)\",\n",
    "    \"objective3\": \"Objective Exam (cont. 2)\",\n",
    "    \"assessment\": \"Assessment\",\n",
    "    \"plan\": \"Plan\",\n",
    "}\n",
    "\n",
    "def _normalize_value(value: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a field value for one-line plain text:\n",
    "    - Treat empty or 'N/A' as empty (to be omitted)\n",
    "    - Collapse whitespace/newlines to single spaces\n",
    "    \"\"\"\n",
    "    if not value:\n",
    "        return \"\"\n",
    "    if value.strip().upper() == \"N/A\":\n",
    "        return \"\"\n",
    "    return \" \".join(value.split())\n",
    "\n",
    "def pretty_note_for_plain_text(fields_dict: dict) -> str:\n",
    "    \"\"\"\n",
    "    Render a single case note as realistic plain text (no bullets):\n",
    "    - Always show section headers\n",
    "    - Only include non-N/A field lines\n",
    "    - Each field is \"Label: value\" on its own line\n",
    "    - Blank line after each section\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for section in SECTION_ORDER:\n",
    "        header = PRETTY_SECTION_LABELS.get(section, SECTION_LABELS.get(section, section))\n",
    "        parts.append(header)  # always show header\n",
    "\n",
    "        fields = REQUIRED_HEADERS[section]\n",
    "        for f in fields:\n",
    "            val = _normalize_value(fields_dict.get(f, \"\"))\n",
    "            if not val:\n",
    "                continue  # omit N/A/empty\n",
    "            parts.append(f\"{f}: {val}\")\n",
    "        parts.append(\"\")  # blank line after section\n",
    "    return \"\\n\".join(parts).strip()\n",
    "\n",
    "def rebuild_case_text_from_ckpt_entry(entry: dict) -> str:\n",
    "    fields = entry.get(\"fields\")\n",
    "    if isinstance(fields, dict) and fields:\n",
    "        return pretty_note_for_plain_text(fields)\n",
    "    return _normalize_value(entry.get(\"note\", \"\") or \"\")\n",
    "\n",
    "def combined_text_from_completed(out_prefix: str) -> str | None:\n",
    "    ckpt = load_checkpoint(out_prefix)\n",
    "    done = []\n",
    "    for k, v in ckpt[\"cases\"].items():\n",
    "        if v.get(\"status\") == \"complete\":\n",
    "            done.append((v.get(\"case_index\", 9999), k, v))\n",
    "    if not done:\n",
    "        print(f\"[{out_prefix}] No completed cases to output.\")\n",
    "        return None\n",
    "\n",
    "    done.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "    doc_parts = []\n",
    "    for case_index, key, entry in done:\n",
    "        # Case title like \"CASE NN — Title\"\n",
    "        try:\n",
    "            tokens = key.split(\" \", 3)\n",
    "            if len(tokens) >= 3 and tokens[0].lower() == \"case\":\n",
    "                num = tokens[1]\n",
    "                title = key.split(\" \", 2)[-1]\n",
    "                if title[:2] == num:\n",
    "                    title = title[2:].strip()\n",
    "                case_title_line = f\"CASE {num} — {title}\"\n",
    "            else:\n",
    "                case_title_line = key\n",
    "        except Exception:\n",
    "            case_title_line = key\n",
    "\n",
    "        underline = \"=\" * len(case_title_line)\n",
    "        doc_parts.append(case_title_line)\n",
    "        doc_parts.append(underline)\n",
    "        doc_parts.append(rebuild_case_text_from_ckpt_entry(entry))\n",
    "        doc_parts.append(\"\")  # blank between cases\n",
    "\n",
    "    return \"\\n\".join(doc_parts).strip()\n",
    "\n",
    "def write_combined_to_doc(out_prefix: str, doc_id: str):\n",
    "    combined_text = combined_text_from_completed(out_prefix)\n",
    "    if combined_text:\n",
    "        replace_doc_with_text(doc_id, combined_text)\n",
    "        print(f\"[{out_prefix}] Updated local Doc with clean plain-text output.\")\n",
    "\n",
    "def write_combined_to_txt(out_prefix: str, filename: str | None = None) -> str | None:\n",
    "    combined_text = combined_text_from_completed(out_prefix)\n",
    "    if not combined_text:\n",
    "        return None\n",
    "    if filename is None:\n",
    "        filename = f\"{out_prefix}_soap_notes_{sanitize_filename(SELECTED_MODEL)}.txt\"\n",
    "    path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(combined_text)\n",
    "    print(f\"[{out_prefix}] Wrote plain-text file:\", path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxzujU78PsLP"
   },
   "outputs": [],
   "source": [
    "# Cell 12: Orchestrate runs with manual start, checkpointing, and outputs (Doc + TXT)\n",
    "\n",
    "def run_cases_with_manual_start(case_dict, out_prefix: str, target_doc_id: str | None = None, start_index: int = 1, max_cases=None):\n",
    "    # Reset checkpoint if requested\n",
    "    if RESET_CHECKPOINTS:\n",
    "        p = checkpoint_path(out_prefix)\n",
    "        if os.path.exists(p):\n",
    "            os.remove(p)\n",
    "            print(f\"Deleted old checkpoint: {p}\")\n",
    "\n",
    "    # Items filtered by start_index and optional max_cases\n",
    "    items = [(idx, data) for idx, data in case_dict.items() if idx >= start_index]\n",
    "    items.sort(key=lambda x: x[0])\n",
    "    if max_cases is not None:\n",
    "        items = items[:max_cases]\n",
    "\n",
    "    llm = get_llm()\n",
    "    ckpt = load_checkpoint(out_prefix)\n",
    "    completed_keys = {k for k, v in ckpt[\"cases\"].items() if v.get(\"status\") == \"complete\"} if SKIP_COMPLETED else set()\n",
    "\n",
    "    print(f\"{out_prefix}: starting at case index {start_index}. Total to process this run: {len(items)}\")\n",
    "    try:\n",
    "        for idx, case in tqdm(items, desc=f\"{SELECTED_MODEL} {out_prefix}\", position=0):\n",
    "            k = case_key(idx, case['title'])\n",
    "            if SKIP_COMPLETED and k in completed_keys:\n",
    "                continue\n",
    "\n",
    "            # Resume partial fields if present\n",
    "            existing = ckpt[\"cases\"].get(k, {})\n",
    "            starting_fields = existing.get(\"fields\", {}) if existing.get(\"status\") in (\"partial\", \"complete\") else {}\n",
    "\n",
    "            fields_done = extract_fields_for_case(llm, case['text'], out_prefix, k, starting_fields=starting_fields, verbose=False)\n",
    "\n",
    "            # Mark complete in checkpoint (final text re-rendered later for Doc/TXT)\n",
    "            ckpt = load_checkpoint(out_prefix)\n",
    "            ckpt[\"cases\"][k] = {\n",
    "                \"status\": \"complete\",\n",
    "                \"fields\": fields_done,\n",
    "                \"title\": k,\n",
    "                \"last_updated\": now_iso(),\n",
    "                \"note\": assemble_note_from_fields_minimal(fields_done),\n",
    "                \"case_index\": idx\n",
    "            }\n",
    "            save_checkpoint(out_prefix, ckpt)\n",
    "\n",
    "        print(f\"\\n[{out_prefix}] Finished processing selected cases.\")\n",
    "    except Exception as e:\n",
    "        if is_quota_or_rate_error(e):\n",
    "            print(f\"\\n[{out_prefix}] Stopping due to quota/rate limit: {e}\")\n",
    "        else:\n",
    "            print(f\"\\n[{out_prefix}] Unexpected error: {e}\")\n",
    "\n",
    "    # Push current completed results to the target local Doc and write TXT mirror\n",
    "            # Only update the local Doc if a doc_id is provided\n",
    "        if target_doc_id:\n",
    "            write_combined_to_doc(out_prefix, target_doc_id)\n",
    "    write_combined_to_txt(out_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-SfsIUAPuUO",
    "outputId": "d93501b1-c053-4a14-98a4-28a9506d6c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted old checkpoint: /content/drive/MyDrive/Ophthalmology Live Folder/Case Study Output/checkpoint_CLEAN_openai.gpt-5-mini-2025-08-07.json\n",
      "CLEAN: starting at case index 1. Total to process this run: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai.gpt-5-mini-2025-08-07 CLEAN: 100%|██████████| 98/98 [4:51:02<00:00, 178.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CLEAN] Finished processing selected cases.\n",
      "Replaced content of Google Doc 1xoVkMUsRF8ozwoBnq9QSJduZcDuAtgE58rn5dqhoPKw (771571 chars).\n",
      "[CLEAN] Updated Google Doc with clean plain-text output.\n",
      "[CLEAN] Wrote plain-text file: /content/drive/MyDrive/Ophthalmology Live Folder/Case Study Output/CLEAN_soap_notes_openai.gpt-5-mini-2025-08-07.txt\n",
      "Deleted old checkpoint: /content/drive/MyDrive/Ophthalmology Live Folder/Case Study Output/checkpoint_ADVERSARIAL_openai.gpt-5-mini-2025-08-07.json\n",
      "ADVERSARIAL: starting at case index 1. Total to process this run: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai.gpt-5-mini-2025-08-07 ADVERSARIAL: 100%|██████████| 98/98 [4:39:04<00:00, 170.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ADVERSARIAL] Finished processing selected cases.\n",
      "Replaced content of Google Doc 1ayKJwGEAG-yPTpz2yyLo0pPSGqnTW4fMcMNeqWdwPVs (727846 chars).\n",
      "[ADVERSARIAL] Updated Google Doc with clean plain-text output.\n",
      "[ADVERSARIAL] Wrote plain-text file: /content/drive/MyDrive/Ophthalmology Live Folder/Case Study Output/ADVERSARIAL_soap_notes_openai.gpt-5-mini-2025-08-07.txt\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Execute runs using your manual start points and limits\n",
    "\n",
    "if RUN_CLEAN and clean_cases:\n",
    "    run_cases_with_manual_start(\n",
    "        clean_cases,\n",
    "        out_prefix=\"CLEAN\",\n",
    "        start_index=START_CLEAN_AT,\n",
    "        max_cases=MAX_CASES_CLEAN\n",
    "    )\n",
    "\n",
    "if RUN_ADVERSARIAL and adversarial_cases:\n",
    "    run_cases_with_manual_start(\n",
    "        adversarial_cases,\n",
    "        out_prefix=\"ADVERSARIAL\",\n",
    "        start_index=START_ADVERSARIAL_AT,\n",
    "        max_cases=MAX_CASES_ADVERSARIAL\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
